{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation learning and predictive analysis for Football managers\n",
    "\n",
    "In this chapter we are going to try to model members of the amateur football club. This is related to one of the author's contributions to a wellbeing of a local football community. The ultimate goal is to split membors into a reasonable teams so that it is as enjoyable and competitive from sport's perspoective as possible.\n",
    "\n",
    "## The challenge\n",
    "\n",
    "For every Sunday's game we organise a poll to see who is joining a game. Coomon agreement is that we need minimum 10 and maximum 18 players - so it means we have a variable size teams.\n",
    "\n",
    "- even though we have started to collect data for our game we still have around 20 games recorded. Distribution of the players also changed over the course of the recoring period so we have even less data for every single player. \n",
    "\n",
    "## The plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input, initializers\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "    \n",
    "from competition_manager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)                  # Fix NumPy random seed\n",
    "    random.seed(seed)                     # Fix Python built-in random seed\n",
    "    tf.random.set_seed(seed)              # Fix TensorFlow random seed\n",
    "\n",
    "    # Optional but recommended: configure TensorFlow for deterministic ops\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# Call this function at the very start, before building or training your model\n",
    "seed_value = 42\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic teams and games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating team's strength based on players individual strengths and rule-based interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_team_strength(team_players):\n",
    "    # Base strength sum\n",
    "    strength = player_strengths[team_players].sum()\n",
    "    print(f\"Base strength of team {team_players}: {strength:.4f}\")\n",
    "    \n",
    "    # Compute favorite player boost (fixed)\n",
    "    for i, pair in enumerate(friend_pairs):\n",
    "        if all(player in team_players for player in pair):\n",
    "            boost = friend_pairs_boost[i]\n",
    "            strength += boost\n",
    "            print(f\"Favorite pair boost applied for players {pair}: +{boost:.4f}, total strength now {strength:.4f}\")\n",
    "    for i, triplet in enumerate(friend_triplets):\n",
    "        if all(player in team_players for player in triplet):\n",
    "            boost = friend_triplets_boost[i]\n",
    "            strength += boost\n",
    "            print(f\"Favorite triplet boost applied for players {triplet}: +{boost:.4f}, total strength now {strength:.4f}\")\n",
    "    \n",
    "    # Compute skills boost correlated with players' average strength\n",
    "    for i, pair in enumerate(skilled_pairs):\n",
    "        if all(player in team_players for player in pair):\n",
    "            avg_strength = player_strengths[list(pair)].mean()\n",
    "            boost = skilled_pairs_boost[i] * avg_strength\n",
    "            strength += boost\n",
    "            print(f\"Skills pair boost for players {pair}: avg strength {avg_strength:.4f} * boost factor {skilled_pairs_boost[i]:.4f} = +{boost:.4f}, total strength now {strength:.4f}\")\n",
    "    \n",
    "    for i, triplet in enumerate(skilled_triplets):\n",
    "        if all(player in team_players for player in triplet):\n",
    "            avg_strength = player_strengths[list(triplet)].mean()\n",
    "            boost = skilled_triplets_boost[i] * avg_strength\n",
    "            strength += boost\n",
    "            print(f\"Skills triplet boost for players {triplet}: avg strength {avg_strength:.4f} * boost factor {skilled_triplets_boost[i]:.4f} = +{boost:.4f}, total strength now {strength:.4f}\")\n",
    "    \n",
    "    return strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the teams, friend pairs/triplets and skills pairs/triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "NUM_PLAYERS = 30  # player 0 is ignore/masked and 1 is added to account for this\n",
    "MIN_TEAM_SIZE = 5\n",
    "MAX_TEAM_SIZE = 9\n",
    "NUM_GAMES = 100\n",
    "\n",
    "# 1. Generate players' strengths: single float number [0, 1]\n",
    "player_strengths = np.random.rand(NUM_PLAYERS + 1) # player 0 is ignore/masked \n",
    "\n",
    "# 2. Generate favorite player pairs and triplets (friends)\n",
    "num_friend_pairs = 10\n",
    "num_friend_triplets = 5\n",
    "\n",
    "# Randomly select unique pairs\n",
    "friend_pairs = [tuple(np.random.choice(np.arange(1, NUM_PLAYERS +1), size=2, replace=False)) for _ in range(num_friend_pairs)]\n",
    "friend_pairs_boost = np.random.uniform(0.05, 0.15, size=num_friend_pairs)  # small boost\n",
    "\n",
    "# Randomly select unique triplets\n",
    "friend_triplets = [tuple(np.random.choice(np.arange(1, NUM_PLAYERS +1), size=3, replace=False)) for _ in range(num_friend_triplets)]\n",
    "friend_triplets_boost = np.random.uniform(0.1, 0.25, size=num_friend_triplets)  # larger boost\n",
    "\n",
    "# 3. Generate skilled pairs and triplets (high skill synergy)\n",
    "num_skilled_pairs = 8\n",
    "num_skilled_triplets = 4\n",
    "\n",
    "skilled_pairs = [tuple(np.random.choice(np.arange(1, NUM_PLAYERS + 1), size=2, replace=False)) for _ in range(num_skilled_pairs)]\n",
    "skilled_pairs_boost = np.random.uniform(0.1, 0.2, size=num_skilled_pairs)  # moderate boost\n",
    "\n",
    "skilled_triplets = [tuple(np.random.choice(np.arange(1, NUM_PLAYERS + 1), size=3, replace=False)) for _ in range(num_skilled_triplets)]\n",
    "skilled_triplets_boost = np.random.uniform(0.15, 0.3, size=num_skilled_triplets)  # strong boost\n",
    "\n",
    "# 2. Prepare arrays to hold the dataset\n",
    "teamA_data = np.zeros((NUM_GAMES, MAX_TEAM_SIZE), dtype=int)\n",
    "teamB_data = np.zeros((NUM_GAMES, MAX_TEAM_SIZE), dtype=int)\n",
    "labels = np.zeros(NUM_GAMES)\n",
    "\n",
    "def drop_zeroes_for_sum(players_strengths):\n",
    "    return players_strengths[players_strengths !=0]\n",
    "\n",
    "for game_i in range(NUM_GAMES):\n",
    "    # Random sizes for both teams in [MIN_TEAM_SIZE, MAX_TEAM_SIZE]\n",
    "\n",
    "    team_size = np.random.randint(MIN_TEAM_SIZE, MAX_TEAM_SIZE + 1)\n",
    "\n",
    "    # Randomly sample distinct players for each team (sampling with replacement allowed for simplicity)\n",
    "    # To avoid overlap if needed: sample without replacement from full 32 for both teams combined,\n",
    "    # here assuming players can appear on both teams (as per original conversation)\n",
    "    # teamA_players = np.random.choice(NUM_PLAYERS, size=teamA_size, replace=False)\n",
    "    # teamB_players = np.random.choice(NUM_PLAYERS, size=teamB_size, replace=False)\n",
    "    \n",
    "    # Shuffle all players and split into two disjoint teams\n",
    "    all_players = np.random.permutation(np.arange(1, NUM_PLAYERS + 1))\n",
    "    teamA_players = all_players[:team_size]\n",
    "    teamB_players = all_players[team_size:2*team_size]\n",
    "    \n",
    "    print(f\"Game # {game_i} evaluation: \")\n",
    "    # Compute team strengths as sum of player strengths\n",
    "    teamA_strength = calculate_team_strength(teamA_players)\n",
    "    teamB_strength = calculate_team_strength(teamB_players)\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    # print(f\"Team A strengths {player_strengths[teamA_players]} Total: {teamA_strength}\")\n",
    "\n",
    "    # Calculate match outcome: 1 if Team A wins, 0 if Team B wins\n",
    "    # Add small noise to simulate unpredictability\n",
    "    outcome = teamA_strength - teamB_strength + np.random.normal(scale=0.1)\n",
    "    labels[game_i] = outcome\n",
    "\n",
    "    # Pad teams to max size using zeros (which corresponds to masked player)\n",
    "    teamA_data[game_i, :team_size] = teamA_players\n",
    "    teamB_data[game_i, :team_size] = teamB_players\n",
    "\n",
    "print(\"player_strengths shape:\", player_strengths.shape)\n",
    "print(\"teamA_data shape:\", teamA_data.shape)\n",
    "print(\"teamB_data shape:\", teamB_data.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "\n",
    "# Example print first 3 games\n",
    "for i in range(3):\n",
    "    print(f\"Game {i}:\")\n",
    "    teamA_pls = teamA_data[i]\n",
    "    print(\" Team A players: \", teamA_pls)\n",
    "    print(\" Team A palyers' stregths: \", player_strengths[teamA_pls])\n",
    "\n",
    "    teamB_pls = teamB_data[i]\n",
    "    print(\" Team B players: \", teamB_pls)\n",
    "    print(f\"Team B strengths {drop_zeroes_for_sum(player_strengths[teamB_pls]).sum()}\")\n",
    "    print(\" Team B palyers' stregths: \", player_strengths[teamB_pls])\n",
    "    print(\" Label (Team A wins=1):\", labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants (adjust as needed)\n",
    "PLAYER_EMB_DIM = 32\n",
    "# NUM_CLASSES = 1  # Binary: win/loss\n",
    "\n",
    "# Inputs: variable-length teams\n",
    "teamA_input = Input(batch_shape=(80, 9), dtype='int32', name='teamA')  # variable-length\n",
    "teamB_input = Input(batch_shape=(80, 9), dtype='int32', name='teamB')  # variable-length\n",
    "\n",
    "# Embedding layer with mask support\n",
    "player_embedding = layers.Embedding(\n",
    "    input_dim=NUM_PLAYERS + 1,\n",
    "    output_dim=PLAYER_EMB_DIM,\n",
    "    embeddings_initializer=initializers.GlorotUniform(seed=seed_value),\n",
    "    mask_zero=True,  # Important: enables automatic masking for padding (0 as pad token)\n",
    "    # embeddings_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "    name='player_embedding'\n",
    ")\n",
    "\n",
    "# Embed team players\n",
    "teamA_embeds = player_embedding(teamA_input)  # shape: (batch, teamA_len, emb_dim)\n",
    "teamB_embeds = player_embedding(teamB_input)\n",
    "\n",
    "#Self-attention block (respects masks automatically if using Functional API)\n",
    "def self_attention_block(x, name_prefix=''):\n",
    "    attn_output = layers.MultiHeadAttention(\n",
    "        num_heads=4,\n",
    "        key_dim=PLAYER_EMB_DIM,\n",
    "        dropout=0.1,\n",
    "        name=f'{name_prefix}_attn'\n",
    "    )(x, x)\n",
    "    x = layers.Add(name=f'{name_prefix}_residual')([x, attn_output])\n",
    "    x = layers.LayerNormalization(name=f'{name_prefix}_norm')(x)\n",
    "    return x\n",
    "\n",
    "# # Apply attention\n",
    "teamA_attn = self_attention_block(teamA_embeds, 'teamA')\n",
    "teamB_attn = self_attention_block(teamB_embeds, 'teamB')\n",
    "\n",
    "# Global average pooling over valid (non-padded) tokens\n",
    "# TF handles masking automatically in GlobalAveragePooling1D if mask_zero=True\n",
    "teamA_vector = layers.GlobalAveragePooling1D(name='teamA_avgpool')(teamA_attn)\n",
    "teamB_vector = layers.GlobalAveragePooling1D(name='teamB_avgpool')(teamB_attn)\n",
    "teamA_vector = teamA_vector\n",
    "teamB_vector = teamB_vector \n",
    "\n",
    "# Matchup modeling (difference vector)\n",
    "matchup_vector = layers.Subtract(name='matchup_diff')([teamA_vector, teamB_vector])\n",
    "\n",
    "# Concatenate summary representation\n",
    "match_input = layers.Concatenate(name='match_features')([teamA_vector, teamB_vector, matchup_vector])\n",
    "# match_input = layers.Concatenate(name='match_features')([teamA_vector, teamB_vector])\n",
    "\n",
    "# Feedforward classification head\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(match_input)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='linear', name='regression_output')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[teamA_input, teamB_input], outputs=output)\n",
    "model.compile(optimizer='adam', \n",
    "                loss='mean_squared_error',   # or 'mean_absolute_error'\n",
    "                metrics=['mean_absolute_error']\n",
    "                )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume the following arrays from your dataset generation code:\n",
    "# teamA_data, teamB_data, labels (all np arrays)\n",
    "\n",
    "# 1. Train-validation split (80% train, 20% validation)\n",
    "X_trainA, X_valA, X_trainB, X_valB, y_train, y_val = train_test_split(\n",
    "    teamA_data, teamB_data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Build or import your Keras model (reuse the model creation code from before)\n",
    "# For example, let's say you have your variable-size team transformer model as 'model'\n",
    "\n",
    "# 3. Optional: callbacks for monitoring\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define a learning rate schedule function (step decay example)\n",
    "def lr_schedule(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 10\n",
    "    if epoch > 0 and epoch % epochs_drop == 0:\n",
    "        return lr * drop_rate\n",
    "    return lr\n",
    "\n",
    "#Instantiate callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Or adaptive reduction on plateau (reduce LR when val_loss stalls)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                 patience=5, min_lr=1e-6)\n",
    "\n",
    "\n",
    "player_embedding_layer = model.get_layer(\"player_embedding\")\n",
    "embeddings_before_fold = player_embedding_layer.get_weights()[0]\n",
    "print(\"Embedding vector for player zero before training:\", embeddings_before_fold[0])\n",
    "\n",
    "print(X_trainA)\n",
    "\n",
    "# 4. Train the model\n",
    "history = model.fit(\n",
    "    [X_trainA, X_trainB],                 # Inputs as a list\n",
    "    y_train,                              # Targets\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_valA, X_valB], y_val),\n",
    "    callbacks=[lr_scheduler, reduce_lr, early_stop],\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "pe_layer = model.get_layer(\"player_embedding\")\n",
    "embeddings_after_fold = pe_layer.get_weights()[0]\n",
    "print(\"Embedding vector for player zero after training:\", embeddings_after_fold[0])\n",
    "\n",
    "change = np.linalg.norm(embeddings_after_fold[0] - embeddings_before_fold[0])\n",
    "print(\"Change in player zero embedding vector:\", change)\n",
    "\n",
    "# 5. Evaluate model performance\n",
    "loss, accuracy = model.evaluate([X_valA, X_valB], y_val)\n",
    "print(f\"Validation accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume 'history' is the object returned by your call to model.fit(...)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mean_absolute_error')\n",
    "plt.title('Training vs Validation MAE')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting embeddings of players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct reference to layer\n",
    "player_embeddings = player_embedding.get_weights()[0]\n",
    "print(player_embeddings.shape)  # (NUM_PLAYERS, PLAYER_EMB_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP and visualizing players in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "# Generate test embeddings and labels (replace these with actual data)\n",
    "np.random.seed(42)\n",
    "# player_embeddings = np.random.rand(32, 32)\n",
    "# labels = [f'{name}' for name in team_dict.values()]\n",
    "labels_points = [f'Player {idx}:{name}' for idx, name in enumerate(player_strengths)]\n",
    "\n",
    "\n",
    "# Embed to 3D\n",
    "reducer = umap.UMAP(n_components=3, random_state=None, n_jobs=-1)\n",
    "embeddings_3d = reducer.fit_transform(player_embeddings)\n",
    "\n",
    "# Create interactive 3D scatter plot\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter3d(\n",
    "        x=embeddings_3d[:, 0],\n",
    "        y=embeddings_3d[:, 1],\n",
    "        z=embeddings_3d[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=7,\n",
    "            color=player_strengths,       # Color by this array\n",
    "            colorscale='Viridis',         # Choose a colorscale\n",
    "            colorbar=dict(title='Strength'),\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=labels_points,          # Hover labels\n",
    "        hoverinfo='text'\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D UMAP projection of player embeddings\",\n",
    "    width=1000,             # <-- Change this to your desired width in pixels\n",
    "    height=800,  \n",
    "    scene=dict(\n",
    "        xaxis_title=\"UMAP-1\",\n",
    "        yaxis_title=\"UMAP-2\",\n",
    "        zaxis_title=\"UMAP-3\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation of the embeddings with the original base strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Assuming these variables from your setup:\n",
    "# player_strengths: numpy array of shape (num_players,)\n",
    "# embeddings_3d: numpy array of shape (num_players, 3) -- UMAP 3D projections\n",
    "\n",
    "num_players = player_strengths.shape[0]\n",
    "correlations = []\n",
    "print(player_strengths.shape)\n",
    "print(embeddings_3d[:, 0].shape)\n",
    "for dim in range(3):\n",
    "    corr, p_value = pearsonr(embeddings_3d[:, dim], player_strengths)\n",
    "    correlations.append((corr, p_value))\n",
    "    print(f\"Dimension {dim + 1} correlation with base strengths: r = {corr:.4f}, p-value = {p_value:.4g}\")\n",
    "\n",
    "# Optionally, compute average absolute correlation across all 3 dimensions\n",
    "avg_abs_corr = np.mean([abs(c[0]) for c in correlations])\n",
    "print(f\"Average absolute correlation across 3 components: {avg_abs_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
